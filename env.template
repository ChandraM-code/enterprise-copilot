# ============================================
# Agentic Cache-Driven Application Config
# ============================================
# Copy this file to .env and fill in your values

# ==================== API KEYS ====================
# At least one LLM API key is required

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini Configuration
GOOGLE_API_KEY=your_google_api_key_here


# ==================== REDIS (Layer 0) ====================
# Redis configuration for exact cache

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=


# ==================== QDRANT (Layer 1 & 2) ====================
# Qdrant vector database configuration

QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=


# ==================== LLM CONFIGURATION ====================
# Default LLM provider and models

DEFAULT_LLM=openai
OPENAI_MODEL=gpt-3.5-turbo
GEMINI_MODEL=gemini-pro


# ==================== CACHE SETTINGS ====================
# Cache behavior configuration

# Similarity threshold for semantic cache (0.0 to 1.0)
# Higher = more strict matching
SEMANTIC_SIMILARITY_THRESHOLD=0.85

# Similarity threshold for RAG cache (0.0 to 1.0)
RAG_SIMILARITY_THRESHOLD=0.75

# Time-to-live for Layer 0 cache in seconds
CACHE_TTL=3600


# ==================== EMBEDDING MODEL ====================
# Sentence transformer model for embeddings
# Options: all-MiniLM-L6-v2 (fast), all-mpnet-base-v2 (accurate)

EMBEDDING_MODEL=all-MiniLM-L6-v2

